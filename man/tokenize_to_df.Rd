% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/as_tokens.R
\name{tokenize_to_df}
\alias{tokenize_to_df}
\title{Create a data.frame of tokens}
\usage{
tokenize_to_df(
  sentence,
  doc_id = seq_along(sentence),
  mode = c("C", "B", "A"),
  into = dict_features(),
  col_select = seq_along(into),
  instance = NULL,
  ...
)
}
\arguments{
\item{sentence}{Input text vectors.}

\item{doc_id}{Identifier of input sentences.}

\item{mode}{Split mode (A, B, C)}

\item{into}{Column names of features.}

\item{col_select}{Character or integer vector of column names
that kept in the returned value.}

\item{instance}{This is optional; if you already have an instance of
\verb{<sudachipy.tokenizer.Tokenizer>}, supplying the predefined
instance would improve the performance.}

\item{...}{Currently not used.}
}
\description{
Create a data.frame of tokens
}
\examples{
\dontrun{
tokenize_to_df(
  "Tokyo, Japan",
  mode = "A",
  into = dict_features("en"),
  col_select = c("POS1", "POS2")
)
}
}
